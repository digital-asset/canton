# Release of Canton 3.3.0

## Whatâ€™s New

### Smart Contract Upgrading

The Smart Contract Upgrade feature enables fixing application bugs or extending Daml models is possible without downtime
or breaking Daml clients. It was introduced in Daml v2.9.1 and is now available in Daml and Canton 3.3.

This feature is well-suited for developing and rolling out incremental template updates. There are guidelines to ensure
upgrade compatibility between DAR files. The compatibility is checked at compile time, DAR upload time, and runtime.
This is to ensure data backwards compatibility and forward compatibility (subject to the guidelines being followed)
so that DARs can be safely upgraded to new versions. It also prevents unexpected data loss if a runtime downgrade occurs
(e.g., a ledger client is using template version 1.0.0 while the participant node has the newer version 1.1.0).

### Ledger API Universal Streams

Currently, a Ledger API client can subscribe to ledger events and receive either a flat transaction stream or
a transaction tree stream where neither provides a complete view. Subscribing to topology events is not available either.
Universal Event Streams is a new feature that overcomes these challenges while also providing additional filtering
and formatting capabilities.

The Universal Even Streams feature provides transaction filters and streams with the following capabilities:
- Merging of flat and tree transaction capabilities.
- Explicit list of event types to be included in the stream.
- Extending the list of event properties that can be turned on and off.

It combines the topology and package information into a single continuous stream of updates ordered by their offsets.
Future events will be added in a backwards compatible manner.

## Breaking Changes

### Rename of Domain to Synchronizer

Rename of "domain" into "synchronizer" in the entire codebase including console commands, gRPC messages, error codes.

### Automatic Node Initialization and Configuration

In case you have been using manual identity initialization of a node, i.e., using ``auto-init = false``, you will be impacted by the following change in automatic node initialization.

The node initialization has been modified to better support root namespace keys and using static identities
for our documentation. Mainly, while before, we had the ``init.auto-init`` flag, we now support a bit more
versatile configurations.

The config structure looks like this now:
```
canton.participants.participant.init = {
    identity = {
        type = auto
        identifier = {
            type = config // random // explicit(name)
        }
    }
    generate-intermediate-key = false
    generate-topology-transactions-and-keys = true
}
```

A manual identity can be specified via the gRPC API if the configuration is set to ``manual``.
```
identity = {
    type = manual
}
```

Alternatively, the identity can be defined in the configuration file, which is equivalent to an
API based initialization using the ``external`` config:
```
    identity = {
        type = external
        identifier = name
        namespace = "optional namespace"
        delegations = ["namespace delegation files"]
    }
```

The old behaviour of ``auto-init = false`` (or ``init.identity = null``) can be recovered using
```
canton.participants.participant1.init = {
    generate-topology-transactions-and-keys = false
    identity.type = manual
}
```

This means that auto-init is now split into two parts: generating the identity and generating
the subsequent topology transactions.

Additionally, the console command ``node.topology.init_id`` has been changed slightly too:
It now supports additional parameters ``delegations`` and ``delegationFiles``. These can be used
to specify the delegations that are necessary to control the identity of the node, which means that
the ``init_id`` call combined with ``identity.type = manual`` is equivalent to the
``identity.type = external`` in the config, except that one is declarative via the config, the
other is interactive via the console. In addition, on the API level, the ``InitId`` request now expects
the ``unique_identifier`` as its components, ``identifier`` and ``namespace``.

The `init_id` repair macro has been renamed to `init_id_from_uid`. `init_id` still exists but takes the identifier as a string and namespace optionally instead.

### Interactive Submission

The interactive submission service and external signing authorization logic are now always enabled. The following configuration fields must be removed from the participant's configuration:
  - `ledger-api.interactive-submission-service.enabled`
  - `parameters.enable-external-authorization`

The hashing algorithm for external signing has been updated from V1 to V2 (3.3 will only support V2) in a non backward-compatible way:
- There is a new `interfaceId` field in the `Fetch` node of the transaction that now is part of the hash.
- The hashing scheme version (now being V2) is now part of the hash

See the [hashing algorithm documentation](https://docs.digitalasset-staging.com/build/3.3/explanations/external-signing/external_signing_hashing_algorithm#fetch) for the updated version.
The hash provided as part of the `PrepareSubmissionResponse` is updated to the new algorithm as well.

This updated algorithm is supported under a new `V2` hashing scheme version.
Support for `V1` has been dropped and will not be supported in Canton 3.3 onward.
This is relevant for applications that re-compute the hash client-side.
Such applications must update their implementation in order to use the interactive submission service on Canton 3.3.

- The `ProcessedDisclosedContract` message in the `Metadata` message of the `interactive_submission_service.proto` file has been renamed to `InputContract`, and the
  field `disclosed_events` in the same `Metadata` message renamed to `input_contracts` to better represent its content.
- Input contracts available on the preparing participant can now be used to prepare a command (it was previously required to explicitly disclose all input contracts in the `prepare` request)
  If some input contracts are missing from both the participant local store and the explicitly disclosed contracts, the `prepare` call will fail.
- The synchronizer ID is now optional and can be omitted in the prepare request. If left empty, a suitable sychronizer will be selected automatically.

### Ledger API

#### Application ID renamed to User ID

Ledger API fields containing application_id have been renamed to user_id. All the associated semantics are kept intact.
One exception is the validation of the user_id field, see ``value.proto`` for the differences.
Canton console and Json API have been adapted accordingly.

#### GetTransactionBy, GetTransactionTreeBy and GetUpdateBy endpoints

- The `GetTransactionByEventId` and `GetTransactionTreeByEventId` methods in the Ledger API update service have been
  replaced by the `GetTransactionByOffset` and the `GetTransactionTreeByOffset` respectively.
- In consequence, the `GetTransactionByEventIdRequest` has been replaced by the `GetTransactionByOffsetRequest` message.
- The `GetTransactionByOffsetRequest` contains the offset of the transaction or the transaction tree to be fetched and
  the requesting parties.
- The Json API endpoints have been adapted accordingly

In the 3.4, the `GetTransactionByOffset`, `GetTransactionTreeByOffset`, `GetTransactionById` and `GetTransactionTreeById`
methods will be phased out completely in favor of `GetUpdateByOffset` and `GetUpdateById`. The new methods make it possible
to look up an update by its offset or id.
- `GetUpdateByOffsetRequest` and `GetUpdateByIdRequest` messages were added. Both contain the update
  format that dictate the attributes of the update. Look at [Ledger API migration guide](https://docs.digitalasset-staging.com/build/3.3/reference/lapi-migration-guide) on how
  use the added messages over the `GetTransactionByOffsetRequest` and `GetTransactionByIdRequest`.
- The `GetUpdateResponse` is the response in both methods. It contains the update, which can be one of:
  - transaction
  - reassignment
  - topology transaction
- The java bindings and Json API were also extended to include the above changes.

#### Changes to submit-and-wait for transactions

- The argument to `SubmitAndWaitForTransaction` call has been changed from `SubmitAndWaitRequest` to
  `SubmitAndWaitForTransactionRequest`.
- Apart from the `Commands`, this message contains the `TransactionFormat` that defines the attributes of the transaction
  to be returned. For more details please see the migration guide.

#### Extensions to the reassignment support

- `SubmitAndWaitForReassignment` call has been added, it allows submitting reassignment commands and waiting until
  it has been successfully sequenced by the participant.
- The `SubmitAndWaitForReassignmentRequest` message was added that contains the reassignment commands to be submitted and
  the `EventFormat` that defines how the `Reassignment` will be presented.
- `SubmitReassignmentRequest` used by the `CommandSubmissionService` in the `SubmitReassignment` call now accepts
  a batch of reassignment commands rather than just one.
- In the update stream, a `Reassignment` now contains a list of events rather than just one.
- The Json API and the java bindings were extended accordingly.

#### Extensions to the topology transaction support

- The `ParticipantAuthorizationAdded` message was added to distinguish the first time the participant acquires
  permission to a party from the change of that permission (represented by `ParticipantAuthorizationChanged`).
- The `TopologyEvent` message was extended to include the `ParticipantAuthorizationAdded`.
- The Json API and the java bindings have changed accordingly to accommodate the changes.

#### Daml Errors

- Ledger API now gives the `DAML_FAILURE` error instead of the `UNHANDLED_EXCEPTION` error when exceptions are thrown
  and not caught in the Daml code.
- It is also possible to raise these errors directly by calling `failWithStatus` method from Daml code.
- The error details are encoded as the `ErrorInfoDetail` metadata. It includes an `error_id` in of the form
  `UNHANDLED_EXCEPTION/Module.Name:ExceptionName` for legacy exceptions, and is fully user defined for errors raised from
  `failWithStatus`.
- Please migrate your code to using `failWithStatus` and away from the daml exceptions before 3.4.

#### Changing offsets from Strings to Integers

The offset is now an int64 which allows trivial and direct comparisons.
- Negative values are considered to be invalid.
- A zero value denotes the participantâ€™s begin offset and the first valid offset is 1.
- The notion of ledger end is no longer available.
- In requesting an ACS, the offset needs to be provided. It should be obtained through a preceding call to getLedgerEnd.


#### Replacing event ids with node ids

- The `event_id` field has been removed and replaced with a `node_id` (int32) from the Event messages:
  - `CreatedEvent`
  - `ArchivedEvent`
  - `ExercisedEvent`
  - `UnassignedEvent`
- The structural representation of daml transaction trees no longer exposes the root event IDs and the children for
  exercised events.
  - `child_event_ids` fields have been removed from the `ExercisedEvent`.
  - `last_descendant_node_id` field has been added in the `ExercisedEvent`. This field specifies the upper boundary for
    the node ids of the events that are consequences of this exercised event.
  - The `root_event_ids` have been replaced with `root_node_ids` in the `TransactionTree`.
- Building a transaction tree is different now as the is-child relationship between nodes is replaced with the is-descendant
  relationship.
  - Heavily filtered transaction trees (tree with gaps) can now be reconstructed when some intermediate nodes are missing
  - This is a more compact representation because it scales better than the vector of children nodes.
- The `events_by_id` field in the `TransactionTree` message has been converted from a `map<string, TreeEvent>` to a
  `map<int32, TreeEvent>` with the keys representing the node ids of the events.
- The Json API and the java bindings were changed accordingly.

#### Deduplication Offset
Before, only absolute offsets were allowed to define the deduplication periods by offset. After the change
participant-begin offsets are also supported for defining deduplication periods. The participant-begin deduplication
period (defined as zero value in API) is only valid to be used if the participant was not pruned yet. Otherwise, as in
the other cases where the deduplication offset is earlier than the last pruned offset, an error informing that
deduplication period starts too early will be returned.

### JSON API

- JSON API v1 is now deprecated in 3.3 and will be removed completely from 3.4.
- openapi.yaml is generated using 3.0.3 version of specification.
- Http response status codes are based on the corresponding gRPC errors where applicable.
- `/v2/users` and `/v2/parties` now support paging.
- openapi.yaml has been updated to correctly represent Timestamps as strings in the JSON API schema.
- Fields that are mapped to `Option`, `Seq` or `Map` in gRPC are no longer required and can be omitted in the request.
  Their value defaults to an empty container.
- `_recordId` fields have been removed from Daml records in Json API.
- `default-close-delay` has been removed from `ws-config` (websocket config) in `http-service` configuration.
  Close delay is no longer necessary.
- Following types are now encoded as strings:
    - `HashingSchemeVersion`,
    - `PackageStatus`,
    - `ParticipantPermission`,
    - `SigningAlgorithmSpec`,
    - `SignatureFormat`,
    - `TransactionShape`,


### ACS Export/Import

The ACS export and import now use an ACS snapshot containing Ledger API active contracts, as opposed to the Canton internal
active contracts. Further, the ACS export now requires a ledger offset for taking the ACS snapshot, instead of an
optional timestamp. The new ACS export does not feature an offboarding flag anymore; offboarding is not ready for production use and
will be addressed in a future release.

For party replication, we want to take (export) the ACS snapshot at the ledger offset when the topology transaction
results in a (to be replicated) party being added (onboarded) on a participant. The new command
`find_party_max_activation_offset` allows to find such offset. Analogously, the new `find_party_max_deactivation_offset`
command allows to find the ledger offset when a party is removed (offboarded) from a participant.

The 3.3 release contains both variants: `export_acs_old`/`import_acs_old` and `export_acs`/`import_acs`.
A subsequent release is only going to contain the Ledger API active contract `export_acs`/`import_acs` commands (and their protobuf
implementation).

- Renamed Canton console commands.
  - Details: Renaming of the current `{export|import}_acs` to the `{export|import}_acs_old` console commands.
- Changed protobuf service and message definitions.
  - Details: Renaming of the `{Export|Import}Acs` rpc together with their `{Export|Import}Acs{Request|Response}`
    messages to the `{Export|Import}AcsOld` rpc together with their `{Export|Import}AcsOld{Request|Response}` messages
    in the `participant_repair_service.proto`
- Deprecation of `{export|import}_acs_old` console commands, its implementation and protobuf representation.
- New endpoint location for the new `export_acs`.
  - Details: The new `export_acs` and its protobuf implementation are no longer part of the participant repair
    administration; but now are located in the participant parties' administration: `party_management_service.proto`.
    Consequently, the `export_acs` endpoint is accessible without requiring a set repair flag.
- Same endpoint location for the new `import_acs`.
  - Details: `import_acs` and its protobuf implementation are still part of the participant repair administration. Thus,
    using it still requires a set repair flag.
- No backwards compatibility for ACS snapshots.
  Details: An ACS snapshot that has been exported with 3.2 needs to be imported with `import_acs_old`.
- Renamed the current `ActiveContact` to `ActiveContactOld`. And deprecation of `ActiveContactOld`, and in particular
  its method to `ActiveContactOld#fromFile`
- Renamed the current `import_acs_from_file` repair macro to `import_acs_old_from_file`. And deprecation of
  `import_acs_old_from_file`.

### Ledger API Index DB Schema Changes

- Index DB schema changed in a non-backwards compatible fashion.

  The offset-related fields (e.g. ledger_offset, ledger_end) that were previously stored as `VARCHAR(4000)` for H2 and
  `text` for Postgres are now stored as `BIGINT` (for both db types).
  - If the offset column can take the value of the participant begin then the column should be null-able and null should
    be stored as the offset value (i.e. no zero values are used to represent the participant begin).
  - Only exception to
    it is the deduplication_offset of the lapi_command_completions which will take the zero value when the participant
    begin must be stored as deduplication offset, since null is used to signify the absence of this field.
- Changed DeduplicationPeriod's offset field type to `int64` in participant_transaction.proto in a non-backwards
  compatible fashion.

  The type of the offset field changed from `bytes` to `int64` to be compatible with the newly introduced integer offset type.

- Renamed the node_index field of events in the index db to node_id.

### Signing Key Usage

The console commands to generate (`generate_signing_key`) and register signing keys (`register_kms_signing_key`) now require a signing key usage parameter `usage: SigningKeyUsage` to specify the intended context in which a signing key is used. This parameter is enforced and ensures that signing keys are only employed for their designated purposes. The supported values are:

  - Namespace: Used for the root and intermediate namespace keys that can sign topology transactions for that namespace.
  - SequencerAuthentication: Used for signing keys that authenticate network members towards the sequencer.
  - Protocol: Used for all signing operations that occur as part of the core protocol. This includes, for example, signing view trees, messages, or data involved in protocol execution.â€œ

### Removed identifier delegation topology request and `IdentityDelegation` key usage

The `IdentifierDelegation` topology request type and its associated signing key usage, `IdentityDelegation`, have
been removed. This usage was previously reserved for delegating identity-related capabilities but is no
longer supported. Any existing keys using the `IdentityDelegation` usage will have it ignored during
deserialization.

All console commands and data types on the admin API related to identifier delegations have been removed.

### NamespaceDelegation can be restricted to a specific set of topology mappings

- `NamespaceDelegation.is_root_delegation` is deprecated and replaced with the `oneof` `NamespaceDelegation.restriction`. See the
  protobuf documentation for more details. Existing `NamespaceDelegation` protobuf values can still be read and the hash of
  existing topology transactions is also preserved. New `NamespaceDelegation`s will only make use of the `restriction` `oneof`.
  transaction is also preserved.
  - The equivalent of `is_root_delegation=true` is `restriction=CanSignAllMappings`.
  - The equivalent of `is_root_delegation=false` is `restriction=CanSignAllButNamespaceDelegations`
- The console command `topology.namespace_delegation.propose_delegation` was changed. The parameter `isRootDelegation: Boolean` is replaced with the parameter
  `delegationRestriction: DelegationRestriction`, which can be one of the following values:
  - `CanSignAllMappings`: This is equivalent to the previously known "root delegation", meaning that the target key of the delegation can be used
    to sign all topology mappings.
  - `CanSignAllButNamespaceDelegations`: This is equivalent to the previously known "non-root delegation", meaning that the target key of the delegation
    can be used to sign all topology mappings other than namespace delegations.
  - `CanSignSpecificMappings(TopologyMapping.Code*)`: The target key of the delegation can only be used to sign the specified mappings.

### `InvalidGivenCurrentSystemStateSeekAfterEnd` error category

The description of existing error category `InvalidGivenCurrentSystemStateSeekAfterEnd` has been generalized.
As such this error category now describes a failure due to requesting a resource using a parameter value that
falls beyond the current upper bound (or 'end') defined by the system's state. For example, a request that asks
for data at a ledger offset which is past the current ledger's end.

With this change, the error category `InvalidGivenCurrentSystemStateSeekAfterEnd` has also been marked as
`retryable`. Because, it makes sense to retry a failed request assuming the system has progressed in the meantime.
For example, new ledger entries have been added; and thus a previously requested ledger offset has become valid.

### Topology Management Minor Breaking Changes

- Topology related error codes have been renamed to contain the prefix `TOPOLOGY_`, for example: `SECRET_KEY_NOT_IN_STORE` -> `TOPOLOGY_SECRET_KEY_NOT_IN_STORE`.
- Renamed the `filter_store` parameter in `TopologyManagerReadService` to `store` because it doesn't act anymore as a string filter like `filter_party`.
- Console commands changed the parameter `filterStore: String` to `store: TopologyStoreId`. Additionally, there
  are implicit conversions in `ConsoleEnvironment` to convert `SynchronizerId` to `TopologyStoreId` and variants thereof (`Option`, `Set`, ...).
  With these implicit conversions, whenever a `TopologyStoreId` is expected, users can pass just the synchronizer id and it will be automatically converted
  into the correct `TopologyStoreId.Synchronizer`.
- `TopologyManagerReadService.ExportTopologySnapshot` and `TopologyManagerWriteService.ImportTopologySnapshot` are now streaming services for exporting and importing a topology snapshot respectively.
- Changed the `signedBy` parameter of the console command `topology.party_to_participant_mapping.propose` from `Optional`
  to `Seq`.

### DAR and Package Services

DarService and Package service on the admin-api have been cleaned up:
  - Before, a DAR was referred through a hash over the zip file. Now, the DAR ID is the main package ID.
  - Renamed all `hash` arguments to `darId`.
  - Added name and version of DAR and package entries to the admin API commands.
  - Renamed the field `source description` to `description` and stored it with the DAR, not the packages.
  - Renamed the command `list_contents` to `get_content` to disambiguate with `list` (both for packages and DARs).
  - Added a new command `packages.list_references` to support listing which DARs are referencing a particular
    package.

- Addressing a DAR on the admin api is simplified: Instead of the DAR ID concept, we directly use the main package-id, which is synonymous.
  - Renamed all `darId` arguments to `mainPackageId`

### Fatal Failures

- A new storage parameter is introduced: `storage.parameters.failed-to-fatal-delay`. This parameter, which defaults to 5 minutes, defines the delay after which a database storage that is continously in a Failed state escalates to Fatal.
  The sequencer liveness health is now changed to use its storage as a fatal dependency, which means that if the storage transitions to Fatal, the sequencer liveness health transitions irrevocably to NOT_SERVING. This allows a monitoring system to detect the situation and restart the node.
  **NOTE** Currently, this parameter is only used by the `DbStorageSingle` component, which is only used by the sequencer.

- In rare cases following a mediator-side sequencer connection `TransportChange` the mediator may result in an inconsistent state (internal error `PreviousTimestampMismatch`) and will crash, in order to be restarted to recover from that inconsistent state.

### Minor Breaking Changes

- Ledger Metering has been removed. This involved
  - deleting MeteringReportService in the Ledger API
  - deleting /v2/metering endpoint in the JSON API
  - deleting the console ledger_api.metering.get_report command
- The package vetting ledger-effective-time boundaries change to validFrom being inclusive and validUntil being exclusive
  whereas previously validFrom was exclusive and validUntil was inclusive.
- Changed the endpoint `PackageService.UploadDar` to accept a list of dars that can be uploaded and vetted together.
  The same change is also represented in the `ParticipantAdminCommands.Package.UploadDar`.
- renamed configuration parameter `session-key-cache-config` to `session-encryption-key-cache`.
- `sequencer_authentication_service` RPCs return failures as gRPC errors instead of a dedicated failure message with status OK.
- display_name is no longer a part of Party data, so is removed from party allocation and update requests in the Ledger API and daml script
- `PartyNameManagement` service was removed from the Admin API
- Renamed request/response protobuf messages of the inspection, pruning, resource management services from `Endpoint.Request` to `EndpointRequest` and respectively for the response types.
- Changes to defaults in ResourceLimits:
  - The fields `max_inflight_validation_requests` and `max_submission_rate` are now declared as `optional uint32`,
    which also means that absent values are not encoded anymore as negative values, but as absent values.
    Negative values will result in a parsing error and a rejected request.
- Moved the `canton.monitoring.log-query-cost` option to `canton.monitoring.logging.query-cost`
- New sequencer connection validation mode `SEQUENCER_CONNECTION_VALIDATON_THRESHOLD_ACTIVE` behaves like `SEQUENCER_CONNECTION_VALIDATON_ACTIVE` except that it fails when the threshold of sequencers is not reached. In Canton 3.2, `SEQUENCER_CONNECTION_VALIDATON_THRESHOLD_ACTIVE` was called `STRICT_ACTIVE`.
- Fixed slow sequencer shapshot query on the aggregate submission tables in the case when sequencer onboarding state
  is requested much later and there's more data accumulated in the table:
  - DB schema change: added fields and indexes to the aggregate submission tables to speed up the snapshot query.

## Functional Changes

### KMS Drivers

AWS KMS and Google Cloud KMS are supported as of Canton v2.7 and in all versions of 3.x in the enterprise editions.
To broaden the support of other KMSs and HSMs, Canton v2.9 introduced a plugin approach, called
KMS Drivers, which allows the implementation of custom integrations.

The feature of KMS Drivers from 2.9 is now available in Canton v3.3 both in the enterprise and community edition.

### Topology-Aware Package Selection

- Topology-aware package selection has been introduced to enhance package selection for smart contract upgrades during command interpretation.
  When enabled, the new logic leverages the topology state of connected synchronizers to optimally select packages for transactions, ensuring they pass vetting checks on counter-participants.

- Topology-aware package selection in command submission is enabled by default.
  To disable, toggle `participant.ledger-api.topology-aware-package-selection.enabled = false`

- A new query endpoint for supporting topology-aware package selection in command submission construction is added to the Ledger API:
  - gRPC: `com.daml.ledger.api.v2.interactive.InteractiveSubmissionService.GetPreferredPackageVersion`
  - JSON: `/v2/interactive-submission/preferred-package-version`


### Ledger API interface query upgrading

Streaming and point-wise queries support for smart contract upgrading:

- Dynamic upgrading of interface filters: on a query for interface `iface`, the Ledger API will deliver events
  for all templates that can be upgraded to a template version that implements `iface`.
  The interface filter resolution is dynamic throughout a stream's lifetime: it is re-evaluated on each DAR upload.
  **Note**: No redaction of history: a DAR upload during an ongoing stream does not affect the already scanned ledger
  for the respective stream. If clients are interested in re-reading the history in light of the upgrades introduced
  by a DAR upload,
  the relevant portion of the ACS view of the client should be rebuilt by re-subscribing to the ACS stream
  and continuing from there with an update subscription for the interesting interface filter.
- Dynamic upgrading of interface views: rendering of interface view values is done using the latest (highest semver)
  package version of the template implementing an interface instance. Packages vetted with validUntil are excluded
  from the selection.
  **Note**: The selected version to be rendered does not change once stream is started, even if the vetting state
  evolves.


### Universal Streams in Ledger API (Backwards compatible changes)

- The `GetActiveContractsRequest` message was extended with the `event_format` field of `EventFormat` type. The
  `event_format` should not be set simultaneously with the `filter` or `verbose` field. Look at [Ledger API migration guide](https://docs.digitalasset-staging.com/build/3.3/reference/lapi-migration-guide).
  on how to achieve the original behaviour.
- The `GetUpdatesRequest` message was extended with the `update_format` field of `UpdateFormat` type.
  - For the `GetUpdateTrees` method it must be unset.
  - For the `GetUpdates` method the `update_format` should not be set simultaneously with the filter or verbose field.
    Look at [Ledger API migration guide](https://docs.digitalasset-staging.com/build/3.3/reference/lapi-migration-guide) on how to achieve the original behaviour.
- The `GetTransactionByOffsetRequest` and the `GetTransactionByIdRequest` were extended with the `transaction_format`
  field of the `TransactionFormat` type.
  - For the `GetTransactionTreeByOffset` or the `GetTransactionTreeById` method it must be unset.
  - For the `GetTransactionByOffset` or the `GetTransactionById` method it should not be set simultaneously with the
    `requesting_parties` field. Look at [Ledger API migration guide](https://docs.digitalasset-staging.com/build/3.3/reference/lapi-migration-guide) on how to achieve the
    original behaviour.
- The `GetEventsByContractIdRequest` was extended with the `event_format` field of the `EventFormat` type. It should not
  be set simultaneously with the `requesting_parties` field. Look at
  [Ledger API migration guide](https://docs.digitalasset-staging.com/build/3.3/reference/lapi-migration-guide) on how to achieve the original behaviour.
- The `UpdateFormat` message was added. It specifies what updates to include in the stream and how to render them.
  ```protobuf
  message UpdateFormat {
    TransactionFormat include_transactions = 1;
    EventFormat include_reassignments = 2;
    TopologyFormat include_topology_events = 3;
  }
  ```
  All of its fields are optional and define how transactions, reassignments and topology events will be formatted. If
  a field is not set then the respective updates will not be transmitted.
- The `TransactionFormat` message was added. It specifies what events to include in the transactions and what data to
  compute and include for them.
  ```protobuf
  message TransactionFormat {
    EventFormat event_format = 1;
    TransactionShape transaction_shape = 2;
  }
  ```
- The `TransactionShape` enum defines the event shape for `Transaction`s and can have two different flavors AcsDelta and
  LedgerEffects.
  ```protobuf
  enum TransactionShape {
    TRANSACTION_SHAPE_ACS_DELTA = 1;
    TRANSACTION_SHAPE_LEDGER_EFFECTS = 2;
  }
  ```
  - AcsDelta

    The transaction shape that is sufficient to maintain an accurate ACS view. This translates to create and archive
    events. The field witness_parties in events are populated as stakeholders, transaction filter will apply accordingly.

  - LedgerEffects

    The transaction shape that allows maintaining an ACS and also conveys detailed information about all exercises.
    This translates to create, consuming exercise and non-consuming exercise. The field witness_parties in events are
    populated as cumulative informees, transaction filter will apply accordingly.
- The `EventFormat` message was added. It defines both which events should be included and what data should be computed
  and included for them.
  ```protobuf
  message EventFormat {
    map<string, Filters> filters_by_party = 1;
    Filters filters_for_any_party = 2;
    bool verbose = 3;
  }
  ```
  - The `filters_by_party` field define the filters for specific parties on the participant. Each key must be a valid
    PartyIdString. The interpretation of the filter depends on the transaction shape being filtered:
    - For **ledger-effects** create and exercise events are returned, for which the witnesses include at least one
      of the listed parties and match the per-party filter.
    - For **transaction and active-contract-set streams** create and archive events are returned for all contracts
      whose stakeholders include at least one of the listed parties and match the per-party filter.
  - The `filters_for_any_party` define the filters that apply to all the parties existing on the participant.
  - The `verbose` flag triggers the ledger to include labels for record fields.
- The `TopologyFormat` message was added. It specifies which topology transactions to include in the output and how to
  render them. It currently contains only the `ParticipantAuthorizationTopologyFormat` field. If it is unset no topology
  events will be emitted in the output stream.
  ```protobuf
    message TopologyFormat {
      ParticipantAuthorizationTopologyFormat include_participant_authorization_events = 1;
    }
  ```
- The added `ParticipantAuthorizationTopologyFormat` message specifies which participant authorization topology
  transactions to include and how to render them. In particular, it contains the list of parties for which the topology
  transactions should be transmitted. If the list is empty then the topology transactions for all the parties will be
  streamed.
  ```protobuf
  message ParticipantAuthorizationTopologyFormat {
    repeated string parties = 1;
  }
  ```
- The `ArchivedEvent` and the `ExercisedEvent` messages were extended with the `implemented_interfaces` field. It holds
  the interfaces implemented by the target template that have been matched from the interface filter query. They are
  populated only in case interface filters with `include_interface_view` are set and the event is consuming for
  exercised events.
- The `Event` message was extended to include additionally the `ExercisedEvent` that can also be present in the
  `TreeEvent`. When the transaction shape requested is AcsDelta then only `CreatedEvent`s and `ArchivedEvent`s are returned, while when the
  LedgerEffects shape is requested only `CreatedEvent`s and `ExercisedEvent`s are returned.
- The java bindings and the json api data structures have changed accordingly to include the changes described above.
- For the detailed way on how to migrate to the new Ledger API please see [Ledger API migration guide](https://docs.digitalasset-staging.com/build/3.3/reference/lapi-migration-guide)


### Session Signing Keys

Added session signing keys for protocol message signing and verification. These are software-based, temporary keys authorized by a long-term key via an additional signature and are valid for a short period. Session keys are designed to be used with a KMS/HSM-based provider to reduce the number of signing operations and, consequently, lower the latency and cost associated with external key management services.

Session signing keys can be enabled and their validity period configured through the Canton configuration using `<node>.parameters.session_signing_keys`.
By default they are currently disabled.

### Initial Topology Snapshot Validation
The initial topology snapshot, both for initializing a new sequencer and for onboarding a new member,
is now validated by the node importing the snapshot.

### Memory check during node startup
A memory check has been introduced when starting the node. This check compares the memory allocated to the container with the -Xmx JVM option.
The goal is to ensure that the container has sufficient memory to run the application.
To configure the memory check behavior, add one of the following to your configuration:

```
canton.parameters.startup-memory-check-config.reporting-level = warn  // Default behavior: Logs a warning.
canton.parameters.startup-memory-check-config.reporting-level = crash // Terminates the node if the check fails.
canton.parameters.startup-memory-check-config.reporting-level = ignore // Skips the memory check entirely.
```

### Traffic Fees and Rate Limiting

A base event cost can now be added to every sequenced submission.
The amount is controlled via a new optional field in the `TrafficControlParameters` called `base_event_cost`.
If not set, the base event cost is 0.

Sequencer acknowledgements do not incur a traffic fee, in order to rate limit acknowledgements the sequencers will now conflate acknowledgements coming from a participant within a time window.
This means that if 2 or more acknowledgements from a given member get submitted during the window,
only the first will be sequenced and the others will be discarded, until the window has elapsed.
The conflate time window can be configured with key `acknowledgements-conflate-window` in the sequencer configuration.
Defaults to 45 seconds.

Example: `sequencers.sequencer1.acknowledgements-conflate-window = "1 minute"`

### Refactored synchronizer connectivity service
Refactored synchronizer connectivity service to have endpoints with limited responsibilities:

- Add: ReconnectSynchronizer to be able to reconnect to a registered synchronizer
- Add: DisconnectAllSynchronizers to disconnect from all connected synchronizers
- Change: RegisterSynchronizer does not allow to fully connect to a synchronizer anymore (only registration and potentially handshake): if you want to connect to a synchronizer, use the other endpoint
- Change: ConnectSynchronizer takes a synchronizer config so that it can be used to connect to a synchronizer for the first time
- Rename: ListConfiguredDomains to ListRegisteredSynchronizers for consistency (and in general: configure(d) -> register(ed))

### Offline Root Namespace Initialization Scripts
Scripts to initialize a participant node's identity using an offline root namespace key have been added to the release artifact
under `scripts/offline-root-key`. An example usage with locally generated keys is available at `examples/10-offline-root-namespace-init`.

### Sequencer Event Buffering

- Added a buffer for serving events that is limited by an upper bound for memory consumption:
    ```hocon
        canton.sequencers.<sequencer>.sequencer.block.writer {
          type = high-throughput // NB: this is required for the writer config to be parsed properly

          // maximum memory the buffered events will occupy
          buffered-events-max-memory = 2MiB // Default value
          // batch size for warming up the events buffer at the start of the sequencer until the buffer is full
          buffered-events-preload-batch-size = 50 // Default value
        }
    ```
  - The previous setting `canton.sequencers.<sequencer>.sequencer.block.writer.max-buffered-events-size` has been removed and has no effect anymore
- The sequencer's payload cache configuration changed slightly to disambiguate the memory-limit config from a number-of-elements config:
    ```hocon
    canton.sequencers.<sequencer>.parameters.caching {
      sequencer-payload-cache {
        expire-after-access = "1 minute" // Default value
        maximum-memory = 200MiB // Default value
      }
    }
    ```
  - The previous setting `canton.sequencers.<sequencer>.parameters.caching.sequencer-payload-cache.maximum-size` has been removed and has no effect anymore.


### Temporary Topology Store

Added the concept of temporary topology stores. A temporary topology store is not connected to any synchronizer store
  and therefore does not automatically submit transactions to synchronizers. Temporary topology stores can be used
  for the synchronizer bootstrapping ceremony to not "pollute" the synchronizer owners' authorized stores. Another use
  case is to upload a topology snapshot and inspect the snapshot via the usual topology read service endpoints.
  - Temporary topology stores can be managed via the services `TopologyManagerWriteService.CreateTemporaryTopologyStore` and `TopologyManagerWriteService.DropTemporaryTopologyStore`.

An example how to use temporary topology stores for bootstrapping are [documented](https://docs.digitalasset-staging.com/subnet/3.3/howtos/configure/manage_synchronizer_entities).

### Performance Optimizations

- We introduced contract key prefetching / bulk loading to improve workloads that fetch many contract keys.
- Reduced the payload size of an ACS commitment from 2kB to 34 bytes.
- Introduced parameter `sequencer.writer.event-write-max-concurrency` (default: 2) to configure the maximum number of events batches that can be written at a time.

### Other Minor Changes

- Added `SequencerConnectionAdministration` to remote mediator instances, accessible e.g. via `mymediator.sequencer_connection.get`
- Changed the console User.isActive to isDeactivated to align with the Ledger API
- Added metric `daml.mediator.approved-requests.total` to count the number of approved confirmation requests
- Removed parameters `sequencer.writer.event-write-batch-max-duration` and `sequencer.writer.payload-write-batch-max-duration` as these are not used anymore.
- Remote console sequencer connection config `canton.remote-sequencers.<sequencer>.public-api`
  now uses the same TLS option for custom trust store as `admin-api` and `ledger-api` sections:
  - new: `tls.trust-collection-file = <existing-file>` instead of undocumented old: `custom-trust-certificates.pem-file`
  - new: `tls.enabled = true` to use system's default trust store (old: impossible to configure) for all APIs
- Authorization service configuration of the Ledger API and admin api is validated. No two services can define
  the same target scope or audience.
